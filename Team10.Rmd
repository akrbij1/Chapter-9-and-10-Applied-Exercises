---
title: "Team 10"
author: "Matthew Sadosuk"
date: "4/1/2021"
output:
  html_document:
    toc: true
    toc_depth: 1
    toc_float: true
    df_print: paged  
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Machine Learning 2 Summary Document {.tabset}


For this exercise in chapter 9 we go back and cover support vector classifiers. 
At the end of the chapter we selected applied exercise 8. This exercise features
the OJ data set, where we will be seeing how purchase price of OJ is affected by
the 17 other variables in the dataset
################################################################################

To start this problem we need to load in the two libraries: ISLR and e1071, which
will give us access to the OJ data set. To keep the results consistent we will set 
the seed. Now we will create a random sample with 800 observations from the OJ
data set and then we will split the data into a test set and training set



```{r}
rm(list = ls())

# 8. This problem involves the OJ data set which is part of the ISLR package
library(ISLR)
library(e1071)
#(a) Create a training set containing a random sample of 800
# observations, and a test set containing the remaining observations.
set.seed(5208)

train <- sample(nrow(OJ), 800)
OJ_train <- OJ[train, ]
OJ_test <- OJ[-train, ]

```

After initializing all of the parameters we can now start to construct the support
vector classifier. In the code below we use the svm function and within the function
we are predicting the purchase price onto the entire dataset,we set the kernel 
to linear, use the training dataset, and set cost = .01. Now we take the summary 
of svm_linear, and see that there are 439 support vectors that lay along the 
hyperplane. 

```{r}
#(b) Fit a support vector classifier to the training data using
# cost=0.01, with Purchase as the response and the other variables
# as predictors. Use the summary() function to produce summary
# statistics, and describe the results obtained.

svm_linear <- svm(Purchase ~ . , kernel = "linear", data = OJ_train, cost = 0.01)
summary(svm_linear)

```


In this step I created a function that would store the model, dataset, and the object
being classified.Inside the function is create a variable called confusion_matrix
that creates a table of predicted values from the linear model and the OJ_train 
dataset. Within that function i return the mse calculation that takes the values 
from the new variable confusion_matrix. Finally you concatenate the results, 
which you times 100 by the calc_error_rate that uses the stored values that were
stored in the function. 

```{r}
#(c) What are the training and test error rates?

# calculate error rate
calc_error_rate <- function(svm_model, dataset, true_classes) {
  confusion_matrix <- table(predict(svm_model, dataset), true_classes)
  return(1 - sum(diag(confusion_matrix)) / sum(confusion_matrix))
}

cat("Training Error Rate:", (1 - calc_error_rate(svm_linear, OJ_train, OJ_train$Purchase)) * 100, "%\n")
cat("Test Error Rate:", (1 - calc_error_rate(svm_linear, OJ_test, OJ_test$Purchase)) * 100, "%\n")

```

In this step we will tune the svm model to try to improve the accuracy of the model.
In the function we specify the model type = svm, y-variable, data = OJ, kernel = linear,
and then display range of costs from .01 to 10. After this we will look at the summary
of svm_tune to see what the best performance number was. 


```{r}
#(d) Use the tune() function to select an optimal cost. Consider values in the range 0.01 to 10.
set.seed(5208)

svm_tune <- tune(svm, Purchase ~ . , data = OJ_train, kernel = "linear", 
                 ranges = list(cost = seq(0.01, 10)))
summary(svm_tune)
```


In this step we look at the summary of svm_tune and look to see what cost gives
the best performance in the model. From looking at the summary list it looked to be
a cost of 5.01 gave the best performance. So to make sure this is correct we now
use the best.parameters test method to identify the best cost. After this we
look at the training and test error rates to see how the tune we did above improved
or hurt the model accuracy

```{r}
#(e) Compute the training and test error rates using this new value for cost.
svm_linear2 <- svm(Purchase ~ . , kernel = "linear", 
                  data = OJ_train, cost = svm_tune$best.parameters)

cat("Training Error Rate:", (1 - calc_error_rate(svm_linear2, OJ_train, OJ_train$Purchase)) * 100, "%\n")
cat("Test Error Rate:", (1 - calc_error_rate(svm_linear2, OJ_test, OJ_test$Purchase)) * 100, "%\n")

```


For steps f and g we will follow the same steps that were done in b to e. The only
input being changed in the model is the kernel which will be set to radial in f
and poly for the second one. At the end I will compare the test and train error rate
results and publish which model will be the best


In part c and e we are still using the function that was made above, but the only
part we will be changing is the name of the model to the new svm variable. 

```{r}
#(f) Repeat parts (b) through (e) using a support vector machine with a radial kernel. Use the default value for gamma.
# part b: fitting the support vector 
set.seed(5208)
svm_radial <- svm(Purchase ~ . , data = OJ_train, kernel = "radial")
summary(svm_radial)

# part c: Calculating the test and error rate
cat("Training Error Rate:", 100 * calc_error_rate(svm_radial, OJ_train, OJ_train$Purchase), "%\n")
cat("Test Error Rate:", 100 * calc_error_rate(svm_radial, OJ_test, OJ_test$Purchase), "%\n")

# part d: Adding the costs from .01 to 10
set.seed(5208)
svm_tune2 <- tune(svm, Purchase ~ . , data = OJ_train, kernel = "radial",
                 ranges = list(cost = seq(0.01, 10)))
summary(svm_tune)

# part e: Take the best performance from part d and set that equal to the cost input
svm_radial2 <- svm(Purchase ~ . , data = OJ_train, kernel = "radial",
                  cost = svm_tune$best.parameters)

cat("Training Error Rate:", 100 * calc_error_rate(svm_radial2, OJ_train, OJ_train$Purchase), "%\n")
cat("Test Error Rate:", 100 * calc_error_rate(svm_radial2, OJ_test, OJ_test$Purchase), "%\n")

```





```{r}
#(g) Repeat parts (b) through (e) using a support vector machine with a polynomial kernel. Set degree=2.

# part b: fitting the support vector 
set.seed(5208)

svm_poly <- svm(Purchase ~ . , data = OJ_train, kernel = "poly", degree = 2)
summary(svm_poly)

# part c: Calculating the test and error rate
cat("Training Error Rate:", 100 * calc_error_rate(svm_poly, OJ_train, OJ_train$Purchase), "%\n")
cat("Test Error Rate:", 100 * calc_error_rate(svm_poly, OJ_test, OJ_test$Purchase), "%\n")

# part d: Adding the costs from .01 to 10

set.seed(5208)
svm_tune3 <- tune(svm, Purchase ~ . , data = OJ_train, kernel = "poly", 
                 degree = 2, ranges = list(cost = seq(0.01, 10)))
summary(svm_tune)

# part e: Take the best performance from part d and set that equal to the cost input

svm_poly2 <- svm(Purchase ~ . , data = OJ_train, kernel = "poly", 
                degree = 2, cost = svm_tune$best.parameters$cost)

cat("Training Error Rate:", 100 * calc_error_rate(svm_poly2, OJ_train, OJ_train$Purchase), "%\n")
cat("Test Error Rate:", 100 * calc_error_rate(svm_poly2, OJ_test, OJ_test$Purchase), "%\n")
```


(h) Overall, which approach seems to give the best results on this data?

Overall, radial basis kernel seems to be producing minimum misclassification 
error on training set but the linear kernel performs better on test data.



# Chapter 10 applied exercise {.tabset}
